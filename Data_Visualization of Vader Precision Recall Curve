import csv
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_curve

import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer
nltk.download('vader_lexicon')

def sentiment_scores(sentence):
    sid_obj = SentimentIntensityAnalyzer()
    sentiment_dict = sid_obj.polarity_scores(sentence)
    # Return the compound score which represents the overall sentiment
    return sentiment_dict['compound']

def analyze_csv_sentiments(csv_file_path):
    true_labels = []
    sentiment_scores_list = []

    with open(csv_file_path, 'r', encoding='utf-8') as file:
        csv_reader = csv.reader(file)
        next(csv_reader)  # Skip the header row
        for row in csv_reader:
            # Assuming each row has a column with text to analyze
            # and another column with true sentiment labels
            # Modify the indices if the text and labels are in different columns
            sentence = row[0]
            true_label = int(row[1])  # Assuming sentiment labels are 0 (negative) or 1 (positive)
            true_labels.append(true_label)

            sentiment_score = sentiment_scores(sentence)
            sentiment_scores_list.append(sentiment_score)

    # Calculate precision and recall for different thresholds
    precisions, recalls, thresholds = precision_recall_curve(true_labels, sentiment_scores_list)

    # Plot precision-recall curve
    plt.figure(figsize=(8, 6))
    plt.plot(recalls, precisions, marker='.')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.grid(True)
    plt.show()

if __name__ == "__main__":
    # Path to your CSV file
    csv_file_path = 'C:\\Users\\ethan\\Downloads\\Review, Sentiment - Sheet1 (2).csv'
    analyze_csv_sentiments(csv_file_path)
